{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd92dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88349d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x):\n",
    "    return ((2*x[:, 0].unsqueeze(1)) + 3) + (3 * x[:, 1].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd162e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(shape, low=-1.0, high=1.0):\n",
    "    return (high - low) * torch.rand(shape) + low\n",
    "\n",
    "def fn(x):\n",
    "    # return np.sin(x) + noise(x.shape, low=0, high=1)\n",
    "    # return np.sin(x) #+ noise(x.shape, low=0, high=1)\n",
    "    # return x*10 #+ noise(x.shape, low=0, high=1)\n",
    "\n",
    "    # return torch.sin(x[:, 0].unsqueeze(1)) + torch.cos(x[:, 1].unsqueeze(1)) + noise(x.shape, low=0, high=1) # x[:, 0] are xs; x[:, 0] are the ys\n",
    "    return ((2*x[:, 0].unsqueeze(1)) + 3) + (3 * x[:, 1].unsqueeze(1))\n",
    "\n",
    "class x_y_ds(Dataset):\n",
    "    def __init__(self, fn, N):\n",
    "        # self.xs = torch.linspace(min, max, N).unsqueeze(1)\n",
    "        # self.ys = fn(self.xs)\n",
    "\n",
    "        self.xs = torch.rand(N, 2)\n",
    "        self.ys = fn(self.xs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.xs[idx], self.ys[idx]\n",
    "    \n",
    "data = x_y_ds(fn, N = 100)\n",
    "training_dataset, test_dataset = random_split(\n",
    "    data, [80, 20]\n",
    ")\n",
    "    \n",
    "train_dataloader = DataLoader(dataset = training_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3ed36164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_hat, y):\n",
    "    return (y_hat - y)**2\n",
    "\n",
    "def loss_grad(y_hat, y):\n",
    "    return 2 * (y_hat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a2cb5764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train loss = 16.8647 | test loss = 12.0301\n",
      "Epoch 5 | train loss = 1.4253 | test loss = 1.0281\n",
      "Epoch 10 | train loss = 0.1536 | test loss = 0.1209\n",
      "Epoch 15 | train loss = 0.0463 | test loss = 0.0437\n",
      "Epoch 20 | train loss = 0.0342 | test loss = 0.0343\n",
      "Epoch 25 | train loss = 0.0302 | test loss = 0.0308\n",
      "Epoch 30 | train loss = 0.0272 | test loss = 0.0280\n",
      "Epoch 35 | train loss = 0.0246 | test loss = 0.0255\n",
      "Epoch 40 | train loss = 0.0223 | test loss = 0.0232\n",
      "Epoch 45 | train loss = 0.0201 | test loss = 0.0212\n",
      "Epoch 50 | train loss = 0.0182 | test loss = 0.0193\n",
      "Epoch 55 | train loss = 0.0164 | test loss = 0.0176\n",
      "Epoch 60 | train loss = 0.0148 | test loss = 0.0160\n",
      "Epoch 65 | train loss = 0.0134 | test loss = 0.0146\n",
      "Epoch 70 | train loss = 0.0121 | test loss = 0.0133\n",
      "Epoch 75 | train loss = 0.0110 | test loss = 0.0121\n",
      "Epoch 80 | train loss = 0.0100 | test loss = 0.0111\n",
      "Epoch 85 | train loss = 0.0090 | test loss = 0.0101\n",
      "Epoch 90 | train loss = 0.0081 | test loss = 0.0092\n",
      "Epoch 95 | train loss = 0.0074 | test loss = 0.0084\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "ws = torch.tensor([0.5, 0.6])\n",
    "b = torch.tensor([0.5])\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss_train = 0\n",
    "    num_batches = 0\n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "        bs = y_batch.shape[0]\n",
    "        y_hat = (x_batch @ ws).unsqueeze(1) + b # prediction\n",
    "        losses_train = loss_fn(y_hat, y_batch).mean() # loss\n",
    "        epoch_loss_train += losses_train\n",
    "        # updation\n",
    "        delta = loss_grad(y_hat, y_batch)\n",
    "        ws -= lr * (x_batch.T @ delta).squeeze() / bs\n",
    "        b -= lr * delta.mean()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    epoch_loss_train /= num_batches\n",
    "\n",
    "    # testing\n",
    "    epoch_loss_test = 0\n",
    "    num_batches = 0\n",
    "    for x_batch, y_batch in test_dataloader:\n",
    "        bs = y_batch.shape[0]\n",
    "        y_hat = (x_batch @ ws).unsqueeze(1) + b # prediction\n",
    "        losses_test = loss_fn(y_hat, y_batch).mean() # loss\n",
    "        epoch_loss_test += losses_test\n",
    "        num_batches += 1\n",
    "    epoch_loss_test /= num_batches\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch} | train loss = {epoch_loss_train:.4f} | test loss = {epoch_loss_test:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cf66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
